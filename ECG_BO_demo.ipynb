{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f15fbd76",
   "metadata": {},
   "source": [
    "### Create geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_on = \"jupyter\" # \"jupyter\", \"cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859eeca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if running_on == \"cluster\":\n",
    "    # To run as a python file in cluster\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--patient_number\", help=\"patient to select data\", type=int)\n",
    "    parser.add_argument(\"--N\", help=\"number of training points\", type=int)\n",
    "    parser.add_argument(\"--train_data\", help=\"load_data or compute_points\", type=str)\n",
    "    parser.add_argument(\"--nIter\", help=\"number of iterations\", type=int)\n",
    "    parser.add_argument(\"--criterion\", help=\"criterion for bayesian opt.\", type=str)\n",
    "    parser.add_argument(\"--opt_points\", help=\"load_opt_points or run_opt\", type=str)\n",
    "    # parser.add_argument(\"--var_parameters_list\",\n",
    "                        # nargs='+',\n",
    "                        # help=\"parameters to find, select from: init_length, length, fascicles_length, fascicles_angles, branch_angle\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    patient_number       = args.patient_number\n",
    "    N                    = args.N\n",
    "    obtain_training_data = args.train_data\n",
    "    nIter                = args.nIter\n",
    "    criterion_bo         = args.criterion\n",
    "    optimization_points  = args.opt_points\n",
    "    # var_parameters_list = args.var_parameters_list\n",
    "    \n",
    "elif running_on == \"jupyter\":\n",
    "    # To run on jupyter\n",
    "    patient_number       = \"demo\"\n",
    "    N                    = 250 # 3 #\n",
    "    obtain_training_data = \"load_data\" # \"compute_points\" #\n",
    "    nIter                = 300 # 2 #\n",
    "    criterion_bo         = \"EI\" # \"LCB\" # \"LW-LCB\"\n",
    "    optimization_points  = \"load_opt_points\" # \"run_opt\" #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( \"#####################################\")\n",
    "print (f\"Running analysis of patient {patient_number}\")\n",
    "print (f\"N = {N}, {obtain_training_data}            \") \n",
    "print (f\"nIter = {nIter}, {optimization_points}  \")\n",
    "print ( \"#####################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f986ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if running_on == \"cluster\":\n",
    "    # To run as a python file in cluster\n",
    "    import os\n",
    "    import sys\n",
    "    os.chdir('./PurkinjeECG')\n",
    "    sys.path.insert(0, os.getcwd())\n",
    "    \n",
    "elif running_on == \"jupyter\":\n",
    "    %cd ./PurkinjeECG\n",
    "    %reload_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "from bo_purkinje_demo import BO_Purkinje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12dedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if running_on == \"cluster\":\n",
    "    os.chdir('../JAX-BO')\n",
    "    sys.path.insert(0, os.getcwd())\n",
    "    \n",
    "elif running_on == \"jupyter\":\n",
    "    %cd ../JAX-BO\n",
    "\n",
    "from bo_ecg import BO_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from jax import random, lax\n",
    "from jaxbo.models import GP\n",
    "from jaxbo.utils import normalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from jax import ops\n",
    "from scipy.stats import norm\n",
    "\n",
    "onp.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88168be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if running_on == \"cluster\":\n",
    "    os.chdir('../PurkinjeECG')\n",
    "\n",
    "elif running_on == \"jupyter\":\n",
    "    %cd ../PurkinjeECG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059ba6b9",
   "metadata": {},
   "source": [
    "### Create reference tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54696f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if patient_number == \"demo\":\n",
    "    patient = \"data/crtdemo/crtdemo\"\n",
    "#     qrs_in, qrs_fin = 200, 400\n",
    "    meshes_list_pat = [388, 412, 198, 186]\n",
    "\n",
    "else:\n",
    "    raise Exception(\"patient_number must be 'demo'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e4418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo\n",
    "true_parameters_values = {\"patient\"         : patient,\n",
    "                          \"meshes_list\"     : meshes_list_pat, \n",
    "                          \"init_length\"     : 0., \n",
    "                          \"length\"          : 8.,\n",
    "                          \"w\"               : 0.1, \n",
    "                          \"l_segment\"       : 1.,\n",
    "                          \"fascicles_length\": 0., \n",
    "                          \"fascicles_angles\": 0., \n",
    "                          \"branch_angle\"    : 0.15,\n",
    "                          \"N_it\"            : 20}\n",
    "\n",
    "Tree_true      = BO_Purkinje(**true_parameters_values)\n",
    "bo_method_true = BO_ecg(bo_purkinje_tree = Tree_true)\n",
    "\n",
    "if not os.path.exists(\"./output/patient\"+str(patient_number)):\n",
    "    os.makedirs(\"./output/patient\"+str(patient_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774dcba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a reference, load best result found with Bayesian opt. with respect to real patient\n",
    "var_parameters_read = [\"init_length\", \"fascicles_length\", \"fascicles_angles\",\n",
    "                       \"root_time\", \"cv\"]\n",
    "\n",
    "print (\"Reading results of patient 1 ...\")\n",
    "if patient_number == \"demo\":\n",
    "    X_read = np.load(\"./output/patient1/data_X_N_\"+str(250)+\n",
    "                \"_nIter_\"+str(300)+\"_criterion\"+str(criterion_bo)+\"_\"+\n",
    "                \"_\".join(var_parameters_read)+\".npy\")\n",
    "\n",
    "    y_read = np.load(\"./output/patient1/data_y_N_\"+str(250)+\n",
    "                \"_nIter_\"+str(300)+\"_criterion\"+str(criterion_bo)+\"_\"+\n",
    "                \"_\".join(var_parameters_read)+\".npy\")\n",
    "    \n",
    "    X_min = X_read[np.argmin(y_read)]\n",
    "    y_min = np.min(y_read)\n",
    "    \n",
    "\n",
    "var_params_true = {\"init_length\"     : [X_min[0], X_min[1]],\n",
    "                   \"fascicles_length\": [[X_min[2], X_min[3]],\n",
    "                                        [X_min[4], X_min[5]]],\n",
    "                   \"fascicles_angles\": [[X_min[6], X_min[7]],\n",
    "                                        [X_min[8], X_min[9]]],\n",
    "                   \"root_time\"       : X_min[10],\n",
    "                   \"cv\"              : X_min[11]}\n",
    "\n",
    "print (\"Ground truth\")\n",
    "print (f\"X_ground_truth: {var_params_true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fea0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_true, Endo_true, LVtree_true, RVtree_true = bo_method_true.bo_purkinje_tree.run_ECG(n_sim=0, modify=True, side='both', **var_params_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save true trees and endo\n",
    "file_name = f\"./output/patient{patient_number}/\"\n",
    "\n",
    "pickle.dump(ecg_true, open(f\"./output/patient{patient_number}/True_ecg\",\"wb\"))\n",
    "Endo_true.save_pv(file_name+\"True_endo.vtu\")\n",
    "LVtree_true.save(file_name+\"True_LVtree.vtu\")\n",
    "RVtree_true.save(file_name+\"True_RVtree.vtu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrs_in, qrs_fin = 0, len (ecg_true) # in this case we will use the full ecgs\n",
    "ecg_pat_array = ecg_true[qrs_in:qrs_fin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reference_ecg = False\n",
    "\n",
    "if plot_reference_ecg:\n",
    "    fig,axs = plt.subplots(3, 4, figsize=(10,13), dpi=120, sharex=True, sharey=True)\n",
    "    for ax,l in zip(axs.ravel(),ecg_pat_array.dtype.names):\n",
    "        ax.plot(ecg_pat_array[l])\n",
    "        ax.grid()\n",
    "        ax.set_title(l)\n",
    "    #     ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: In bo_ecg.calculate_loss(), cut_fin = 0, as here we compare the full ecgs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian optimization (with jaxbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "\n",
    "def var_parameters_dict(var_parameters_names):\n",
    "    # Parameters to find\n",
    "    var_parameters = {}\n",
    "    \n",
    "    # init_length\n",
    "    if \"init_length\" in var_parameters_names:\n",
    "        lb_init_length                = 30.0 * np.ones(dim)\n",
    "        ub_init_length                = 100.0 * np.ones(dim)\n",
    "        var_parameters[\"init_length\"] = [lb_init_length, ub_init_length, \"uniform\"]\n",
    "\n",
    "    # length\n",
    "    if \"length\" in var_parameters_names:\n",
    "        lb_length                = 4. * np.ones(1)\n",
    "        ub_length                = 12. * np.ones(1)\n",
    "        var_parameters[\"length\"] = [lb_length, ub_length, \"uniform\"]\n",
    "\n",
    "    # w\n",
    "    if \"w\" in var_parameters_names:\n",
    "        lb_w                = 0.05* np.ones(1) # 0.05\n",
    "        ub_w                = 0.25 * np.ones(1) # 0.8\n",
    "        var_parameters[\"w\"] = [lb_w, ub_w, \"uniform\"]\n",
    "\n",
    "    # l_segment\n",
    "    if \"l_segment\" in var_parameters_names:\n",
    "        lb_l_segment                = 1. * np.ones(dim)\n",
    "        ub_l_segment                = 15. * np.ones(dim)\n",
    "        var_parameters[\"l_segment\"] = [lb_l_segment, ub_l_segment, \"uniform\"]\n",
    "\n",
    "    # fascicles_length\n",
    "    if \"fascicles_length\" in var_parameters_names:\n",
    "        lb_fascicles_length                = 2.0 * np.ones(2*dim) # 10 # 2.*dim because there are 2 params per ventricle \n",
    "        ub_fascicles_length                = 50.0 * np.ones(2*dim) # 30\n",
    "        var_parameters[\"fascicles_length\"] = [lb_fascicles_length, ub_fascicles_length, \"uniform\"]\n",
    "\n",
    "    # f_angles\n",
    "    if \"fascicles_angles\" in var_parameters_names:\n",
    "        lb_fascicles_angles                = -1./4. * onp.pi * np.ones(2*dim) # 0.1 # 2.*dim because there are 2 params per ventricle \n",
    "        ub_fascicles_angles                =  3./4. * onp.pi * np.ones(2*dim) # 1.57\n",
    "        var_parameters[\"fascicles_angles\"] = [lb_fascicles_angles, ub_fascicles_angles, \"uniform\"]\n",
    "\n",
    "    # branch_angle\n",
    "    if \"branch_angle\" in var_parameters_names:\n",
    "        lb_branch_angle                = 5. * onp.pi/180. * np.ones(1)\n",
    "        ub_branch_angle                = 45. * onp.pi/180. * np.ones(1)\n",
    "        var_parameters[\"branch_angle\"] = [lb_branch_angle, ub_branch_angle, \"uniform\"]\n",
    "    \n",
    "    # root_time\n",
    "    if \"root_time\" in var_parameters_names:\n",
    "        lb_root_time                = -75. * np.ones(1)\n",
    "        ub_root_time                = 50. * np.ones(1)\n",
    "        var_parameters[\"root_time\"] = [lb_root_time, ub_root_time, \"uniform\"]\n",
    "        \n",
    "    # cv\n",
    "    if \"cv\" in var_parameters_names:\n",
    "        lb_cv                = 2. * np.ones(1)\n",
    "        ub_cv                = 4. * np.ones(1)\n",
    "        var_parameters[\"cv\"] = [lb_cv, ub_cv, \"uniform\"]\n",
    "        \n",
    "    return var_parameters\n",
    "\n",
    "\n",
    "def initial_values(var_parameters_names, patient, meshes_list_pat):\n",
    "    # Initial values for known parameters    \n",
    "    meshes_list  = meshes_list_pat\n",
    "    init_length  = 30\n",
    "    length       = 8. # [mm]\n",
    "    w            = 0.1\n",
    "    l_segment    = 1.0\n",
    "\n",
    "    f_len        = [20.0, 20.0] \n",
    "    f_angles     = [1., 1.] \n",
    "\n",
    "    branch_angle = 0.15 #20. * onp.pi/180. #0.15\n",
    "    N_it         = 20\n",
    "\n",
    "    # Assign 1. to the parameters to find\n",
    "    # init_length\n",
    "    if \"init_length\" in var_parameters_names:\n",
    "        init_length_bo = 1.\n",
    "    else:\n",
    "        init_length_bo = init_length \n",
    "\n",
    "    # length\n",
    "    if \"length\" in var_parameters_names:\n",
    "        length_bo = 1.\n",
    "    else:\n",
    "        length_bo = length # [mm]\n",
    "\n",
    "    # w\n",
    "    if \"w\" in var_parameters_names:\n",
    "        w_bo = 1.\n",
    "    else:\n",
    "        w_bo = w\n",
    "        \n",
    "    # l_segment\n",
    "    if \"l_segment\" in var_parameters_names:\n",
    "        l_segment_bo = 1.\n",
    "    else:\n",
    "        l_segment_bo = l_segment # [mm]\n",
    "\n",
    "    # fascicles_length\n",
    "    if \"fascicles_length\" in var_parameters_names:\n",
    "        f_len_bo = [1., 1.]\n",
    "    else:\n",
    "        f_len_bo = f_len\n",
    "\n",
    "    # f_angles\n",
    "    if \"fascicles_angles\" in var_parameters_names:\n",
    "        f_angles_bo = [1., 1.] \n",
    "    else:\n",
    "        f_angles_bo = f_angles\n",
    "\n",
    "    # branch_angle\n",
    "    if \"branch_angle\" in var_parameters_names:\n",
    "        branch_angle_bo = 1.\n",
    "    else:\n",
    "        branch_angle_bo = branch_angle\n",
    "\n",
    "    parameters_values = {\"patient\"         : patient,\n",
    "                         \"meshes_list\"     : meshes_list, \n",
    "                         \"init_length\"     : init_length_bo, \n",
    "                         \"length\"          : length_bo, \n",
    "                         \"w\"               : w_bo, \n",
    "                         \"l_segment\"       : l_segment_bo, \n",
    "                         \"fascicles_length\": f_len_bo, \n",
    "                         \"fascicles_angles\": f_angles_bo, \n",
    "                         \"branch_angle\"    : branch_angle_bo, \n",
    "                         \"N_it\"            : N_it}\n",
    "    \n",
    "    return parameters_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_parameters_list = [\"init_length\", \"fascicles_length\", \"fascicles_angles\",\"root_time\", \"cv\"]\n",
    "# var_parameters_list = [\"init_length\", \"length\", \"w\", \"fascicles_length\", \"fascicles_angles\",\n",
    "#                        \"branch_angle\", \"root_time\", \"cv\"]\n",
    "\n",
    "assert var_parameters_list == var_parameters_read, \"Variables do not match ground truth variables\"\n",
    "\n",
    "initial_params = initial_values(var_parameters_list, patient, meshes_list_pat)\n",
    "Tree_bo        = BO_Purkinje(**initial_params)\n",
    "bo_method      = BO_ecg(bo_purkinje_tree = Tree_bo)\n",
    "\n",
    "# f is the mse between real (ecg_pat_array) and computed ecg\n",
    "var_parameters = var_parameters_dict(var_parameters_list)\n",
    "f, p_x         = bo_method.mse_jaxbo(ground_truth = ecg_pat_array, variable_parameters = var_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if obtain_training_data == \"compute_points\":\n",
    "    print (\"Computing training points ...\")\n",
    "    t_ini_train = time.time()    \n",
    "\n",
    "    bo_method.y_trees_non_valid = 10.\n",
    "    noise                       = 0.0\n",
    "    X, y                        = bo_method.set_initial_training_data(N, noise)\n",
    "\n",
    "    onp.save(\"./output/patient\"+str(patient_number)+\"/data_X_\"+str(N)+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys())), X)\n",
    "    onp.save(\"./output/patient\"+str(patient_number)+\"/data_y_\"+str(N)+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys())), y)\n",
    "    onp.save(\"./output/patient\"+str(patient_number)+\"/data_noise_\"+str(N)+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys())), noise)\n",
    "    \n",
    "    t_fin_train = time.time()\n",
    "    print(f\"Train time: {t_fin_train - t_ini_train} s\")\n",
    "\n",
    "elif obtain_training_data == \"load_data\":\n",
    "    print (\"Loading training points ...\")\n",
    "\n",
    "    X     = np.load(\"./output/patient\"+str(patient_number)+\"/data_X_\"+str(N)+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys()))+\".npy\") \n",
    "    y     = np.load(\"./output/patient\"+str(patient_number)+\"/data_y_\"+str(N)+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys()))+\".npy\")\n",
    "    noise = np.load(\"./output/patient\"+str(patient_number)+\"/data_noise_\"+str(N)+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys()))+\".npy\")\n",
    "        \n",
    "    bo_method.noise = noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value for non-valid trees\n",
    "valid   = y != 10.\n",
    "y_valid = y[valid]\n",
    "\n",
    "bo_method.y_trees_non_valid = np.max(y_valid) # trees_non_valid \n",
    "\n",
    "mask = np.equal(y, 10.) # in saved files, non-valid trees are saved with y = 10.\n",
    "y    = ops.index_update(y, ops.index[mask], bo_method.y_trees_non_valid)\n",
    "print (f\"y_trees_non_valid = {bo_method.y_trees_non_valid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bo_method.dim == 2:\n",
    "    X_star, XX, YY = bo_method.set_test_data()\n",
    "else:\n",
    "    X_star = bo_method.set_test_data()\n",
    "\n",
    "# Global minimun is known\n",
    "true_x = list(var_params_true.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Bayesian optimization loop\n",
    "options = {'kernel'     : 'Matern12', # 'Matern52'\n",
    "           'criterion'  : criterion_bo, # EI: expected improvement; LW-LCB\n",
    "           'input_prior': p_x,\n",
    "           'kappa'      : 2.0,\n",
    "           'nIter'      : nIter}\n",
    "\n",
    "if optimization_points == \"run_opt\":\n",
    "    print (\"Running optimization ...\")\n",
    "    t_ini_opt = time.time()\n",
    "    \n",
    "    X, y, info_iterations = bo_method.bo_loop(X, y, X_star, true_x, options)\n",
    "    # mean_iterations, std_iterations, w_pred_iterations, a_pred_iterations = info_iterations\n",
    "    \n",
    "    t_fin_opt = time.time()\n",
    "    print (f\"Optimization time: {t_fin_opt - t_ini_opt} s\")\n",
    "    \n",
    "    # Save points obtained from optimization\n",
    "    onp.save(f\"./output/patient{patient_number}/data_X_N_{N}_nIter_{nIter}_criterion{criterion_bo}_\" + \n",
    "             \"_\".join(list(var_parameters.keys())), X)\n",
    "    \n",
    "    onp.save(f\"./output/patient{patient_number}/data_y_N_{N}_nIter_{nIter}_criterion{criterion_bo}_\" + \n",
    "             \"_\".join(list(var_parameters.keys())), y)    \n",
    "    \n",
    "elif optimization_points == \"load_opt_points\":\n",
    "    print (\"Loading optimization points ...\")\n",
    "    bo_method.nIter = nIter\n",
    "    \n",
    "    X = np.load(\"./output/patient\"+str(patient_number)+\"/data_X_N_\"+str(N)+\n",
    "                \"_nIter_\"+str(nIter)+\"_criterion\"+str(options[\"criterion\"])+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys()))+\".npy\")\n",
    "    \n",
    "    y = np.load(\"./output/patient\"+str(patient_number)+\"/data_y_N_\"+str(N)+\n",
    "                \"_nIter_\"+str(nIter)+\"_criterion\"+str(options[\"criterion\"])+\"_\"+\n",
    "                \"_\".join(list(var_parameters.keys()))+\".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of error\n",
    "list_variable_params = \"_\".join(list(var_parameters.keys()))\n",
    "file_name            = f\"./output/patient{patient_number}/BO_N{N}_nIter{nIter}_criterion\"+str(options[\"criterion\"])+ f\"_variableparams_{list_variable_params}\" \n",
    "\n",
    "plot_MSE = False\n",
    "\n",
    "if plot_MSE:\n",
    "    bo_method.plot_mse(X, y, N, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_bo, Endo_bo, LVtree_bo, RVtree_bo = bo_method.update_purkinje_tree(X, y, var_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_best_ecg = False\n",
    "\n",
    "if plot_best_ecg:\n",
    "    # Plot the best ecg found by the BO along with the reference ecg\n",
    "    bo_method.plot_ecg_match(predicted = ecg_bo, filename_match = file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tree\n",
    "Endo_bo.save_pv(file_name+\"_endo.vtu\")\n",
    "LVtree_bo.save(file_name+\"_LVtree.vtu\")\n",
    "RVtree_bo.save(file_name+\"_RVtree.vtu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pairplot_bo = False\n",
    "\n",
    "if plot_pairplot_bo:\n",
    "    # Create columns names for pairplot\n",
    "    df_columns = []\n",
    "    if \"init_length\" in var_parameters.keys():\n",
    "        df_columns += [\"In. Length L\", \"In. Length R\"]\n",
    "        \n",
    "    if \"length\" in var_parameters.keys():\n",
    "        df_columns += [\"Length\"]\n",
    "        \n",
    "    if \"w\" in var_parameters.keys():\n",
    "        df_columns += [\"w\"]\n",
    "        \n",
    "    if \"fascicles_length\" in var_parameters.keys():\n",
    "        df_columns += [\"Fas. Length L1\", \"Fas. Length L2\", \"Fas. Length R1\", \"Fas. Length R2\"]\n",
    "        \n",
    "    if \"fascicles_angles\" in var_parameters.keys():\n",
    "        df_columns += [\"Fas. Angle L1\", \"Fas. Angle L2\", \"Fas. Angle R1\", \"Fas. Angle R2\"]\n",
    "        \n",
    "    if \"branch_angle\" in var_parameters.keys():\n",
    "        df_columns += [\"Branch Angle\"]\n",
    "        \n",
    "    if \"root_time\" in var_parameters.keys():\n",
    "        df_columns += [\"Root time\"]\n",
    "        \n",
    "    if \"cv\" in var_parameters.keys():\n",
    "        df_columns += [\"CV\"]\n",
    "\n",
    "    # Create data frame with training + optimization points\n",
    "    df      = pd.DataFrame(X, columns = df_columns)\n",
    "    df[\"y\"] = y\n",
    "\n",
    "    # Discretize the continuous variable into bins\n",
    "    num_bins       = 5\n",
    "    bin_labels     = [f'Bin {i}' for i in range(1, num_bins + 1)]\n",
    "    df['hue_bins'] = pd.cut(df['y'], bins = num_bins, labels = bin_labels)\n",
    "\n",
    "    # Plot the pairplot with hue as the discretized variable\n",
    "    sns.pairplot(df, hue='hue_bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejection sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_std_ybest_ecgs(X, y, qrs_in, qrs_fin, var_parameters, bo_class, ecg_patient):\n",
    "    print (f\"Find MSE_best curve ...\")\n",
    "\n",
    "    # Find L_best and std_best comparing y_best = min(y) with all ecgs\n",
    "    X_min            = X[np.argmin(y)]\n",
    "    ecg_min, _, _, _ = bo_class.update_purkinje_tree(np.array([X_min]), 1., var_parameters)\n",
    "    print (f\"X_min = {X_min}\")\n",
    "    print (f\"y_min = {np.min(y)}\")\n",
    "\n",
    "    # Compare with ecgs of all times (not with the mean of them, as previously)\n",
    "    mse_values_best = []\n",
    "    names           = list(ecg_patient.keys())\n",
    "    for ecg_ind in np.arange(ecg_patient[names[0]].shape[1]):\n",
    "\n",
    "        ecg_pat_ind = []\n",
    "        for items in list(ecg_patient.items()):\n",
    "            ecg_pat_ind.append(items[1][:,ecg_ind] / 1e3)\n",
    "\n",
    "        ecg_pat_array_ind = onp.rec.fromarrays(ecg_pat_ind, names=names)\n",
    "        ecg_pat_array_ind = ecg_pat_array_ind[qrs_in:qrs_fin]\n",
    "\n",
    "        mse_values_best.append(bo_class.calculate_loss(predicted = ecg_min,\n",
    "                                                       ecg_pat   = ecg_pat_array_ind))\n",
    "\n",
    "#     L_best_data   = np.mean(np.array(mse_values_best))\n",
    "#     std_best_data = np.std(np.array(mse_values_best))\n",
    "    return mse_values_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gp_model(X, y, options, bo_class, X_star_uniform, gp_state = None):\n",
    "    if gp_state is None:\n",
    "        print (\"Train GP model with valid points...\")\n",
    "        valid = y != bo_class.y_trees_non_valid\n",
    "\n",
    "        X_valid = X[valid]\n",
    "        y_valid = y[valid]\n",
    "        \n",
    "        print (f\"{len(X_valid)} valid points\")\n",
    "\n",
    "        rng_key = random.PRNGKey(0)\n",
    "        gp_model = GP(options)\n",
    "\n",
    "        # Fetch normalized training data\n",
    "        norm_batch, norm_const = normalize(X_valid, y_valid, bo_class.bounds)\n",
    "\n",
    "        # Train GP model\n",
    "        t_ini_train = time.time()\n",
    "        rng_key = random.split(rng_key)[0]\n",
    "        opt_params = gp_model.train(norm_batch,\n",
    "                                    rng_key,\n",
    "                                    num_restarts = 5)\n",
    "        t_fin_train = time.time()\n",
    "        print (f\"Training time: {t_fin_train - t_ini_train} s\")\n",
    "\n",
    "        kwargs = {'params': opt_params,\n",
    "                  'batch': norm_batch,\n",
    "                  'norm_const': norm_const,\n",
    "                  'bounds': bo_class.bounds}\n",
    "        #               'kappa': gp_model.options['kappa'],\n",
    "        #               'gmm_vars': gmm_vars,\n",
    "        #               'rng_key': rng_key}\n",
    "        \n",
    "        gp_state = [gp_model, [norm_batch, norm_const], kwargs]\n",
    "\n",
    "    else:\n",
    "        print (\"Re-using gp_model (it is not trained again with the new points X, y)...\")\n",
    "        gp_model               = gp_state[0]\n",
    "        norm_batch, norm_const = gp_state[1]\n",
    "        kwargs                 = gp_state[2]\n",
    "        \n",
    "    # Compute predicted mean and std\n",
    "    t_ini_pred = time.time()\n",
    "\n",
    "    # batches\n",
    "    n_col = 100\n",
    "    assert (len(X_star_uniform)/n_col).is_integer(), \"Modify n_col\"\n",
    "\n",
    "    reshaped_X      = [X_star_uniform[i:i+n_col] for i in range(0, len(X_star_uniform), n_col)]\n",
    "    mean_it, std_it = lax.map(lambda x: gp_model.predict(x, **kwargs),np.array(reshaped_X))\n",
    "    mean_it         = mean_it.reshape((1,-1))[0]\n",
    "    std_it          = std_it.reshape((1,-1))[0]\n",
    "\n",
    "    # # full\n",
    "    # mean_it, std_it = gp_model.predict(X_star_uniform, **kwargs)\n",
    "\n",
    "    t_fin_pred = time.time()\n",
    "    print (f\"Predicting time: {t_fin_pred - t_ini_pred} s\")\n",
    "    \n",
    "    # Obtain ys and sigmas of X_star_uniform (test points with uniform sampling)\n",
    "    ys     = mean_it * norm_const[\"sigma_y\"] + norm_const[\"mu_y\"]\n",
    "    sigmas = std_it * norm_const[\"sigma_y\"]\n",
    "    \n",
    "    # Obtain min values predicted by gp model\n",
    "    X_min             = X[np.argmin(y)]\n",
    "    mean_min, std_min = gp_model.predict(X_min[None,:], **kwargs)\n",
    "\n",
    "    y_gp_best     = mean_min * norm_const[\"sigma_y\"] + norm_const[\"mu_y\"]\n",
    "    sigma_gp_best = std_min * norm_const[\"sigma_y\"] # should be low\n",
    "    \n",
    "    return ys, sigmas, y_gp_best, sigma_gp_best, gp_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_sampling(ys, sigmas, y_gp_best, sigma_gp_best):\n",
    "    # Rejection sampling, the likelihood is obtained comparing with best point\n",
    "\n",
    "    max_likelihood = norm.pdf(x     = 0.,\n",
    "                              loc   = 0.,\n",
    "                              scale = np.sqrt(sigma_gp_best**2 + np.min(sigmas)**2))\n",
    "\n",
    "    key        = random.PRNGKey(0) # onp.random.randint(50)\n",
    "    comparison = random.uniform(key, shape = (ys.shape[0],)) * max_likelihood\n",
    "\n",
    "    likelihoods = norm.pdf(x     = 0.,\n",
    "                           loc   = ys - y_gp_best,\n",
    "                           scale = np.sqrt(sigmas**2 + sigma_gp_best**2))\n",
    "     \n",
    "    accepted_samples = likelihoods > comparison    \n",
    "\n",
    "    print(f\"{accepted_samples.sum()} accepted samples\")\n",
    "    return accepted_samples, comparison, likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accepted_samples(N_samples, X_star_uniform, y_gp_best, accepted_samples, comparison, likelihoods,\n",
    "                           var_parameters, bo_class, tol, observed_samples, confirmed_samples, folder_trees):\n",
    "                           # sigma_gp_best, std_best_data\n",
    "\n",
    "    X_accepted           = X_star_uniform[accepted_samples]\n",
    "    comparison_accepted  = comparison[accepted_samples]\n",
    "    likelihoods_accepted = likelihoods[accepted_samples]\n",
    "    \n",
    "    sorted_indices       = np.argsort(-likelihoods_accepted)\n",
    "\n",
    "    X_accepted           = X_accepted[sorted_indices]\n",
    "    comparison_accepted  = comparison_accepted[sorted_indices]\n",
    "    \n",
    "    X_true_new           = []\n",
    "    Y_true_new           = [] # true value of X_accepted\n",
    "    \n",
    "    if len(confirmed_samples) == 0:\n",
    "        confirmed_samples[\"samples_final\"]  = []\n",
    "        confirmed_samples[\"ecg_final\"]      = []\n",
    "#         confirmed_samples[\"endo_final\"] = []\n",
    "        confirmed_samples[\"Tree_final\"]     = []\n",
    "        confirmed_samples[\"loss_final\"]     = []\n",
    "\n",
    "    print (f\"tolerance: {tol}\")        \n",
    "    \n",
    "    state                = []\n",
    "    observed_samples_new = []\n",
    "\n",
    "    X_ind        = 1\n",
    "    n_candidates = accepted_samples.sum()\n",
    "    for x_accepted, comp in zip(X_accepted, comparison_accepted):\n",
    "\n",
    "        print (f\"Checking point {X_ind}/{n_candidates}\")\n",
    "\n",
    "        observed = False\n",
    "        for obs_elem in observed_samples:\n",
    "            if np.array_equal(obs_elem[0], x_accepted):\n",
    "                print (\"Point already observed\")\n",
    "                observed = True\n",
    "                X_ind   += 1\n",
    "                break\n",
    "                \n",
    "        if observed == True:\n",
    "            continue\n",
    "        \n",
    "        elif observed == False:\n",
    "            try:\n",
    "                ecg_i, endo_i, LVtree_i, RVtree_i = bo_class.update_purkinje_tree(np.array([x_accepted]), \n",
    "                                                                                  1., \n",
    "                                                                                  var_parameters)\n",
    "            except:\n",
    "                print (\"The fascicle goes out of the domain\")\n",
    "                X_true_new.append(x_accepted)\n",
    "                Y_true_new.append(bo_class.y_trees_non_valid)\n",
    "                state.append(\"rejected\")\n",
    "                \n",
    "                observed_samples_new.append([x_accepted, \"non_valid\"])\n",
    "                \n",
    "                X_ind += 1\n",
    "                continue\n",
    "\n",
    "            loss_i, ind_loss_i = bo_class.calculate_loss(predicted         = ecg_i,\n",
    "                                                         cross_correlation = True,\n",
    "                                                         return_ind        = True)\n",
    "            \n",
    "            observed_samples_new.append([x_accepted,\n",
    "                                        [ecg_i, endo_i, LVtree_i, RVtree_i, loss_i, ind_loss_i]])\n",
    "        \n",
    "        y_true = loss_i\n",
    "        print (f\"Loss: {loss_i}\")\n",
    "        \n",
    "        X_true_new.append(x_accepted)\n",
    "        Y_true_new.append(y_true)\n",
    "        \n",
    "        # Accept points such that y_true - y_best < tol\n",
    "        err_value = y_true - y_gp_best\n",
    "        print (f\"y_true - y_gp_best: {err_value}\")\n",
    "\n",
    "        if err_value < tol:\n",
    "            state.append(\"accepted\")\n",
    "            confirmed_samples[\"samples_final\"].append(x_accepted)\n",
    "            confirmed_samples[\"ecg_final\"].append([ecg_i, ind_loss_i])\n",
    "#             confirmed_samples[\"endo_final\"].append([endo_i])\n",
    "            confirmed_samples[\"Tree_final\"].append([LVtree_i, RVtree_i])\n",
    "            confirmed_samples[\"loss_final\"].append(loss_i)\n",
    "            \n",
    "            n_conf = len(confirmed_samples[\"samples_final\"])\n",
    "            print (f\"Sample accepted! (nÂ°{n_conf-1}, {n_conf}/{N_samples})\")\n",
    "        \n",
    "            # If selected, save Trees and propeiko\n",
    "            tree_ind_test = n_conf - 1\n",
    "            \n",
    "            LVtree_i.save(f\"./output/patient{patient_number}\"+\n",
    "                                      folder_trees+\n",
    "                                      f\"/LVtree_N{N}_nIter{nIter}\"+\n",
    "                                      \"_criterion\"+str(options[\"criterion\"])+\n",
    "                                      f\"_{tree_ind_test}.vtu\")\n",
    "            RVtree_i.save(f\"./output/patient{patient_number}\"+\n",
    "                                     folder_trees+\n",
    "                                     f\"/RVtree_N{N}_nIter{nIter}\"+\n",
    "                                     \"_criterion\"+str(options[\"criterion\"])+\n",
    "                                     f\"_{tree_ind_test}.vtu\")\n",
    "            endo_i.save_pv(f\"./output/patient{patient_number}\"+\n",
    "                                     folder_trees+\n",
    "                                     f\"/propeiko_N{N}_nIter{nIter}\"+\n",
    "                                     \"_criterion\"+str(options[\"criterion\"])+\n",
    "                                     f\"_{tree_ind_test}.vtu\")\n",
    "        \n",
    "        else:        \n",
    "            state.append(\"rejected\")\n",
    "            print (\"Sample rejected\")\n",
    "\n",
    "        if len(confirmed_samples[\"samples_final\"]) >= N_samples:\n",
    "            return \"ok\", confirmed_samples\n",
    "\n",
    "        # If we don't add any samples after, let's say 50 iterations, we should stop, \n",
    "        # retrain the GP and then do this again, using the same random number for comparison\n",
    "        n_rej_max = 50 \n",
    "        if len(state) >= n_rej_max and state[-n_rej_max:] == [\"rejected\"] * n_rej_max:\n",
    "            end_time = time.time()\n",
    "            print(f\"Elapsed time: {end_time - start_time}\")\n",
    "\n",
    "            n_conf   = len(confirmed_samples[\"samples_final\"])\n",
    "            print (f\"No sample accepted in the last {n_rej_max} iterations ({n_conf} accepted)\")\n",
    "            \n",
    "            info_final = {\"X_true_new\"       : X_true_new,\n",
    "                          \"Y_true_new\"       : Y_true_new,\n",
    "                          \"Observed_samples\" : observed_samples + observed_samples_new,\n",
    "                          \"Confirmed_samples\": confirmed_samples}\n",
    "            \n",
    "            return \"retrain gp\", info_final\n",
    "        \n",
    "        X_ind += 1\n",
    "    \n",
    "    # all samples were observed\n",
    "    end_time = time.time()\n",
    "    print(f\"Elapsed time: {end_time - start_time}\")\n",
    "\n",
    "    n_conf   = len(confirmed_samples[\"samples_final\"])\n",
    "    print (f\"All samples were observed, but only {n_conf} accepted.\")\n",
    "\n",
    "    info_final = {\"X_true_new\"       : X_true_new,\n",
    "                  \"Y_true_new\"       : Y_true_new,\n",
    "                  \"Observed_samples\" : observed_samples+observed_samples_new,\n",
    "                  \"Confirmed_samples\": confirmed_samples}\n",
    "    \n",
    "    return \"retrain gp\", info_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for finding and accepting \"N_samples\" candidates\n",
    "options = {'kernel'     : 'Matern12', # 'Matern52'\n",
    "           'criterion'  : criterion_bo, # EI: expected improvement; LW-LCB\n",
    "           'input_prior': p_x,\n",
    "           'kappa'      : 2.0,\n",
    "           'nIter'      : nIter}\n",
    "\n",
    "nn           = 5000000 # test points\n",
    "N_samples    = 30 # 2 #\n",
    "tol          = 100.\n",
    "rejection_n  = 1\n",
    "gp_rejection = None\n",
    "obs_samples  = []\n",
    "conf_samples = {}\n",
    "\n",
    "# Folder to save trees\n",
    "folder_trees = f\"/Trees_N{N}_nIter{nIter}_criterion{criterion_bo}_variableparams_{list_variable_params}\"\n",
    "if os.path.exists(f\"./output/patient{patient_number}\"+folder_trees):\n",
    "    shutil.rmtree(f\"./output/patient{patient_number}\"+folder_trees)\n",
    "\n",
    "os.makedirs(f\"./output/patient{patient_number}\"+folder_trees)\n",
    "\n",
    "while True:\n",
    "    print (\"\")\n",
    "    print (f\"Rejection loop {rejection_n}\")\n",
    "\n",
    "    y_best = np.min(y)\n",
    "    \n",
    "    # Uniform sampling\n",
    "    key        = random.PRNGKey(rejection_n - 1) # 0\n",
    "    X_star_uni = bo_method.lb_params + (bo_method.ub_params - bo_method.lb_params) * random.uniform(key, shape = (nn, bo_method.dim))\n",
    "\n",
    "    # Train with valid points\n",
    "    ys, sigmas, y_gp_best, sigma_gp_best, gp_rejection = train_gp_model(X,\n",
    "                                                                        y,\n",
    "                                                                        options,\n",
    "                                                                        bo_class       = bo_method,\n",
    "                                                                        X_star_uniform = X_star_uni,\n",
    "                                                                        gp_state       = None) # gp_rejection (to not re-train in each loop)\n",
    "\n",
    "    accepted_samples, comparison, likelihoods = rejection_sampling(ys,\n",
    "                                                                   sigmas,\n",
    "                                                                   y_gp_best,\n",
    "                                                                   sigma_gp_best)\n",
    "\n",
    "    state_final, info_final = check_accepted_samples(N_samples         = N_samples,\n",
    "                                                     X_star_uniform    = X_star_uni,\n",
    "                                                     y_gp_best         = y_gp_best,\n",
    "                                                     accepted_samples  = accepted_samples,\n",
    "                                                     comparison        = comparison,\n",
    "                                                     likelihoods       = likelihoods,\n",
    "                                                     var_parameters    = var_parameters,\n",
    "                                                     bo_class          = bo_method,\n",
    "                                                     tol               = tol,\n",
    "                                                     observed_samples  = obs_samples,\n",
    "                                                     confirmed_samples = conf_samples,\n",
    "                                                     folder_trees      = folder_trees)\n",
    "    \n",
    "    if state_final == \"ok\":\n",
    "        samples_final  = info_final[\"samples_final\"]\n",
    "        ecg_final      = info_final[\"ecg_final\"]\n",
    "#         endo_final = info_final[\"endo_final\"]\n",
    "        Tree_final     = info_final[\"Tree_final\"]\n",
    "        loss_final     = info_final[\"loss_final\"]\n",
    "\n",
    "        onp.save(f\"./output/patient{patient_number}/rejection_X_N_{N}_nIter_{nIter}_criterion_{criterion_bo}_nn_{nn}_tol_{tol}_rejection_n_{rejection_n}\", X)\n",
    "        onp.save(f\"./output/patient{patient_number}/rejection_y_N_{N}_nIter_{nIter}_criterion_{criterion_bo}_nn_{nn}_tol_{tol}_rejection_n_{rejection_n}\", y)\n",
    "        \n",
    "        break\n",
    "        \n",
    "    elif state_final == \"retrain gp\":\n",
    "        obs_samples  = info_final[\"Observed_samples\"]\n",
    "        conf_samples = info_final[\"Confirmed_samples\"]        \n",
    "        \n",
    "        X_new = info_final[\"X_true_new\"]\n",
    "        y_new = info_final[\"Y_true_new\"]\n",
    "        y_new = np.asarray(y_new)\n",
    "        \n",
    "        X = np.concatenate([X, np.array(X_new)], axis = 0)\n",
    "        y = np.concatenate([y, y_new], axis = 0)\n",
    "        \n",
    "        assert len(X_new) == len(y_new), \"Something is wrong\"\n",
    "        print (f\"Retrain the gp model with {len(X_new)} new points\")\n",
    "\n",
    "    if rejection_n == 50:\n",
    "        onp.save(f\"./output/patient{patient_number}/rejection_X_N_{N}_nIter_{nIter}_criterion_{criterion_bo}_nn_{nn}_tol_{tol}_rejection_n_{rejection_n}\", X)\n",
    "        onp.save(f\"./output/patient{patient_number}/rejection_y_N_{N}_nIter_{nIter}_criterion_{criterion_bo}_nn_{nn}_tol_{tol}_rejection_n_{rejection_n}\", y)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(\"Elapsed time: \" + str(end_time - start_time))\n",
    "        raise Exception(f\"It was not possible to find and check {N_samples} samples\")\n",
    "    \n",
    "    rejection_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_final = True\n",
    "\n",
    "if save_final:\n",
    "    pickle.dump(ecg_final, open(f\"./output/patient{patient_number}/ecg_N{N}_nIter{nIter}_criterion{criterion_bo}_variableparams_{list_variable_params}\",\"wb\"))\n",
    "    onp.save(f\"./output/patient{patient_number}/X_final_N{N}_nIter{nIter}_criterion{criterion_bo}_variableparams_{list_variable_params}.npy\",samples_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Elapsed time: {end_time - start_time} s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
